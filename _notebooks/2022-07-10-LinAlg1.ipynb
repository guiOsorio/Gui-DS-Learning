{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c80d57",
   "metadata": {},
   "source": [
    "# Linear Algebra #1\n",
    "> Vector norm and matrix multiplication\n",
    "\n",
    "- toc: true\n",
    "- branch: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Gui Osorio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4853bdf",
   "metadata": {},
   "source": [
    "## Vector Norm/Magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be60995",
   "metadata": {},
   "source": [
    "Vector norm refers to calculating a vector's length. In practice, higher coefficients lead to less accurate models, therefore vector norm calculation is useful in ML, as it can be used in techniques to calibrate ML models -> minimizing the loss and preventing overfitting and underfitting. As the distance between two vectors is a single vector, claculating the resulting vector's norm can also be used as a loss function of a ML model.\n",
    "\n",
    "Common methods to calculate a vector's norm are:\n",
    "- L1 norm\n",
    "- L2 norm (root mean squared error)\n",
    "- Max norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33eef61",
   "metadata": {},
   "source": [
    "### L1 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75390b8d",
   "metadata": {},
   "source": [
    "Refers to the sum of absolute values in a vector. Summarizes the distance from the vector to its origin in space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf566a",
   "metadata": {},
   "source": [
    "#### Single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee4f79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0d0b472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From scratch:  6.0\n",
      "Using NumPy.linalg:  6.0\n"
     ]
    }
   ],
   "source": [
    "# Two methods to calculate L1 norm for a single vector as a NumPy array\n",
    "# Define a vector\n",
    "v = np.array([1,2,3])\n",
    "\n",
    "# Calculate L1 from scrach\n",
    "def calc_l1norm(vec): return float(abs(vec.sum()))\n",
    "print('From scratch: ', calc_l1norm(v))\n",
    "\n",
    "# Calculate L1 norm using NumPy\n",
    "print('Using NumPy.linalg: ', np.linalg.norm(v, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28837c36",
   "metadata": {},
   "source": [
    "In the case above, the L1 norm can be calculated with the simple addition: 1 + 2 + 3 = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057587ed",
   "metadata": {},
   "source": [
    "#### Two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afabd34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From scratch:  tensor(3.)\n",
      "Using PyTorch:  tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# Two me#### Example with a single vectorthods to calculate L1 norm for two vectors as PyTorch tensors\n",
    "# Define 2 tensors\n",
    "t1 = torch.tensor([1.,2.,3.])\n",
    "t2 = torch.tensor([4.,5.,6.])\n",
    "\n",
    "# Calculate L1 norm from scratch\n",
    "def calc_l1norm2(tensor1, tensor2): return (tensor1-tensor2).abs().mean()\n",
    "print('From scratch: ', calc_l1norm2(t1,t2))\n",
    "\n",
    "# Calculate L1 norm using PyTorch\n",
    "print('Using PyTorch: ', F.l1_loss(t1, t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51774737",
   "metadata": {},
   "source": [
    "1. Subtract tensors -> t1 - t2 = [-3.,-3.,-3.]\n",
    "2. Convert to absolute values -> [3.,3.,3.].\n",
    "3. The L1 norm of this vector can then be calculated as taking the mean of these values -> (3+3+3)/3 = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9b7f2",
   "metadata": {},
   "source": [
    "### L2 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fa4183",
   "metadata": {},
   "source": [
    "Refers to the root mean squared error of the values in a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5cc11e",
   "metadata": {},
   "source": [
    "#### Single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51c6359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From scratch:  3.7416573867739413\n",
      "Using NumPy.linalg:  3.7416573867739413\n"
     ]
    }
   ],
   "source": [
    "# Calculating L2 norm in a single vector as a NumPy array\n",
    "# Define a vector\n",
    "v = np.array([1.,2.,3.])\n",
    "\n",
    "# Calculate L2 from scratch\n",
    "def calc_l2norm(vec): return np.sqrt(((vec)**2).sum())\n",
    "print('From scratch: ', calc_l2norm(v))\n",
    "\n",
    "# Calculate L2 norm using NumPy\n",
    "print('Using NumPy.linalg: ', np.linalg.norm(v, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bf8e1",
   "metadata": {},
   "source": [
    "1. The vector is transformed into its squared version [1**2, 2**2, 3**3] -> [1,4,9].\n",
    "2. The squared vector is summed up 1 + 4 + 9 -> 14\n",
    "3. The L2 is equal to the square root of the scalar sqrt(14) -> 3.742"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56055a3",
   "metadata": {},
   "source": [
    "#### Two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "937957a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From scratch:  tensor(3.)\n",
      "Using PyTorch:  tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# Calculating L2 norm between two vectors as PyTorch tensors\n",
    "# Define 2 tensors\n",
    "t1 = torch.tensor([1.,2.,3.])\n",
    "t2 = torch.tensor([4.,5.,6.])\n",
    "\n",
    "# Calculate L2 norm from scratch\n",
    "def calc_l2norm2(tensor1, tensor2): return ((tensor1-tensor2)**2).mean().sqrt()\n",
    "print('From scratch: ', calc_l2norm2(t1, t2))\n",
    "\n",
    "# Calculate L2 norm using PyTorch\n",
    "print('Using PyTorch: ', F.mse_loss(t1, t2).sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9a147",
   "metadata": {},
   "source": [
    "1. Subtract tensors -> [1-4,2-5,3-6] -> [-3,-3,-3]\n",
    "2. Square the subtracted tensor -> [-3**2,-3**2,-3**2] -> [9,9,9]\n",
    "3. Calculate the mean as a scalar -> (9+9+9)/3 = 9\n",
    "4. Calculate the square root of the scalar -> sqrt(9) = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0febf0",
   "metadata": {},
   "source": [
    "### Max norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aca172",
   "metadata": {},
   "source": [
    "Returns the maximum absolute value of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7c2d8",
   "metadata": {},
   "source": [
    "#### Single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "576cb2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From scratch:  3\n",
      "Using NumPy:  3.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate max norm for a single vector as a NumPy array\n",
    "# Define vector\n",
    "v = np.array([1,2,3])\n",
    "\n",
    "# Calculate max norm from scratch\n",
    "def calc_maxnorm(vec): return max(abs(vec))\n",
    "print('From scratch: ', calc_maxnorm(v))\n",
    "\n",
    "# Calculate max norm using NumPy.linalg\n",
    "print('Using NumPy: ', np.linalg.norm(v, np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232cabd8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2e22ed3",
   "metadata": {},
   "source": [
    "## Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0510642",
   "metadata": {},
   "source": [
    "Matrix multiplication is not so straight-forward as you may think. Below, I will explain the dot product between matrixes. The conventional multiplication you may be thinking of, when referred to vectors, is called the Hadamard multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f43d5fd",
   "metadata": {},
   "source": [
    "### Matrix-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3ba05b",
   "metadata": {},
   "source": [
    "Let's say we have two matrixes, M1 and M2. Their dimensions (rows, columns) are (m,n) for M1 and (n,k) for M2.\n",
    "For them to be multiplied, a simple requirement needs to be satisfied: n must be equal, that is, the number of columns in M1 needs to be equal to the number of rows in M2.\n",
    "The resulting matrix will be of dimensions (m,k), that is, the number of rows of M1, and the number of columns of M2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55e6fd",
   "metadata": {},
   "source": [
    "Let's represent this by multiplying a 2x3 matrix with a 3x2 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f2996418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "------------\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22, 28],\n",
       "       [49, 64]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix-matrix multiplication\n",
    "M1 = np.array([[1,2,3], [4,5,6]]) # 2x3 matrix\n",
    "M2 = np.array([[1,2], [3,4], [5,6]]) # 3x2 matrix\n",
    "print(M1)\n",
    "print('------------')\n",
    "print(M2)\n",
    "M1 @ M2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89856282",
   "metadata": {},
   "source": [
    "As noted above, the resulting matrix has dimensions (2,2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91445c97",
   "metadata": {},
   "source": [
    "- Position [0,0] = M1[0,0] * M2[0,0] + M1[0,1] * M2[1,0] + M1[0,2] * M2[2,0] = 1 * 1 + 2 * 3 + 3 * 5 = 22\n",
    "- Position [0,1] = M1[0,0] * M2[0,1] + M1[0,1] * M2[1,1] + M1[0,2] * M2[2,1] = 1 * 2 + 2 * 4 + 3 * 6 = 28\n",
    "- Position [1,0] = M1[1,0] * M2[0,0] + M1[1,1] * M2[1,0] + M1[1,2] * M2[2,0] = 4 * 1 + 5 * 3 + 6 * 5 = 49\n",
    "- Position [1,1] = M1[1,0] * M2[0,1] + M1[1,1] * M2[1,1] + M1[1,2] * M2[2,1] = 4 * 2 + 5 * 4 + 6 * 6 = 64\n",
    "- Resulting in the 2x2 matrix [ [22,28], [49,64] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4125aa88",
   "metadata": {},
   "source": [
    "### Matrix-Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58300368",
   "metadata": {},
   "source": [
    "For a matrix-vector multiplication to work, the number of values in the vector needs to equal n, the number of columns in the matrix. Multiplying a matrix of dimensions (m, n) with a vector of k values results in a vector with m values (number of rows in matrix). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c82354fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "------------\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([14, 32])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1,2,3])\n",
    "print(v)\n",
    "print('------------')\n",
    "print(M1)\n",
    "M1 @ v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0f3f3",
   "metadata": {},
   "source": [
    "- Position [0,0] = M1[0,0] * v[0] + M1[0,1] * v[1] + M1[0,2] * v[2] = 1 * 1 + 2 * 2 + 3 * 3 = 14\n",
    "- Position [0,1] = M1[1,0] * v[0] + M1[1,1] * v[1] + M1[1,2] * v[2] = 4 * 1 + 5 * 2 + 6 * 3 = 32\n",
    "- Resulting in a vector with 2 values [14, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ec114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
